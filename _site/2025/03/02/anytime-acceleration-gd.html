<!DOCTYPE html>
<html>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="/assets/js/mathjax-config.js" defer></script>
  <script id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script> 

     
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Anytime Acceleration of Gradient Descent</title>
        <meta name="viewport" content="width=device-width">

        
        <!-- Custom CSS -->
        <link rel="stylesheet" href="/assets/css/post.css">
        
    </head>

    <body>
        <header class="site-header">

            <div class="wrap">
                
              <div style="float:left; margin-top:10px; margin-right:10px;">
                
              </div>

              <div class="site-nav"><nav>
                  <div class="menu-item">
                    <a href="/blog.html" >Blog
                    </a>
                  </div>

              </nav></div>
          
              
            </div>
          
          </header>

    <div class="page-content">
      <div class="wrap">
        <div class="post">

            <header class="post-header">
              <h1>Anytime Acceleration of Gradient Descent</h1>
              <p class="meta">Mar 2, 2025 â€¢ Kaizhao Liu</p>
            </header>
          
            <article class="post-content">
            <p>This is my note on the paper <a href="arxiv.org/abs/2411.17668">Anytime Acceleration of Gradient Descent</a>.</p>

<h1 id="introduction">Introduction</h1>

<p>In my previous note <a href="/2024-05-04-classical-gradient-descent.markdown">Classical Gradient Descent Analysis</a>, we have encountered the analysis of gradient descent with fixed stepsize $\eta$ on</p>

\[\min_{x\in\RR^d} f(x)\]

<p>where $f$ is smooth and convex. Here the question is, if the stepsize $\eta_t$ is not fixed, is it possible to achieve a faster rate then $1/t$?</p>

<h3 id="basic-inequality-for-smooth-convex-functions">Basic Inequality for Smooth Convex Functions</h3>

<p>For a $L$-smooth convex function, we first establish the following inequality</p>

\[f(y)\geq f(x)+\left\langle \nabla f(x), y-x\right\rangle +\frac{1}{2L}\|\nabla f(y)-\nabla f(x)\|^2\]

<p>This can be proved by noting that</p>

\[g_x(y):=f(x)+\left\langle \nabla f(x), y-x\right\rangle\]

<p>is also a convex $L$-smooth function and $x$ is its global minimum.
Then</p>

\[g_x(x)\leq g_x\left(y-\frac{\nabla g_x(y)}{L}\right).\]

<p>From an optimization point of view,
co-coercivities</p>

\[Q_{ij}:=2(f_i-f_j)+2\left\langle g_j, x_j-x_i\right\rangle -\|g_j-g_i\|^2.\]

<p>generate all possible long-range consistency constraints on the objective function $f$.
In other words, the co-coercivity conditions generate all possible valid inequalities with which one can prove convergence rates for GD.</p>

<h1 id="intuition-two-step-case">Intuition: Two-Step Case</h1>

<p><a href="arxiv.org/abs/2309.07879">Acceleration by Stepsize Hedging I: Multi-Step Descent and the Silver Stepsize Schedule</a></p>

<h1 id="silver-stepsize-schedule">Silver Stepsize Schedule</h1>

<p>In <a href="arxiv.org/abs/2309.16530">Acceleration by Stepsize Hedging II: Silver Stepsize Schedule for Smooth Convex Optimization</a>,</p>

<p>where $n=2^k-1$, $r_k=\frac{1}{4\rho^{2k}-3}$, and the learning</p>

<p>The authors exhibit explicit non-negative multipliers $\lambda_{ij}$ satisfying the following identity</p>

\[\sum_{i\neq j\in\{0,\cdots,n,*\}}\lambda_{ij}Q_{ij}=\|x_0-x^*\|^2-\|x_n-\frac{g_n}{2r_k} -x^*\|^2+\frac{f^*-f_n}{r_k}.\]

<p>This immediately implies</p>

\[f_n-f^*\leq r_k \|x_0-x^*\|^2.\]

<p>When $n=0$, the identity is</p>

\[\lambda_{*0}Q_{*0}+\lambda_{0*}Q_{0*}=\|x_0-x^*\|^2-\|x_0-g_0 -x^*\|^2+2(f^*-f_0)\]

<p>which holds if $\lambda_{<em>0}=1$ and $\lambda_{0</em>}=0$.</p>

<p>When $n=1$,</p>

<p>For larger horizons $n$, we construct $\lambda_{ij}$ via recursive gluing.</p>

<h1 id="primitive-stepsize-schedule">Primitive Stepsize Schedule</h1>

            </article>
          


      </div>
    </div>

    <footer class="site-footer">

        <div class="wrap">

      
          <div class="footer-col-2 column">
            
          </div>
      
      
        </div>
      
      </footer>

    </body>
</html>
