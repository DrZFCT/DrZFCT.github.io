<!DOCTYPE html>
<html>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="/assets/js/mathjax-config.js" defer></script>
  <script id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script> 

     
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Matrix Game</title>
        <meta name="viewport" content="width=device-width">

        
        <!-- Custom CSS -->
        <link rel="stylesheet" href="/assets/css/post.css">
        
    </head>

    <body>
        <header class="site-header">

            <div class="wrap">
                
              <div style="float:left; margin-top:10px; margin-right:10px;">
                
              </div>

              <div class="site-nav"><nav>
                  <div class="menu-item">
                    <a href="/blog.html" >Blog
                    </a>
                  </div>

              </nav></div>
          
              
            </div>
          
          </header>

    <div class="page-content">
      <div class="wrap">
        <div class="post">

            <header class="post-header">
              <h1>Matrix Game</h1>
              <p class="meta">Jun 1, 2024 • Kaizhao Liu, Zhekun Shi</p>
            </header>
          
            <article class="post-content">
            <p>RLHF (Reinforcement Learning from Human Feedback) has been the dominant technique to align an intelligent agent to human preferences.</p>

<p>Recently, google has proposed Nash Learning from Human Feedback, which formulated the preference alignment problem into a self-play game.</p>

<h1 id="von-neumanns-minimax-theorem">von Neumann’s Minimax Theorem</h1>

<p>Let $X \subset \mathbb{R}^n$ and $Y \subset \mathbb{R}^m$ be compact convex sets. If $f: X \times Y \rightarrow \mathbb{R}$ is a continuous function that is concave-convex, i.e.,</p>

<p>$f(\cdot, y): X \to \mathbb{R}$ is concave for fixed $y$, and</p>

<p>$f(x, \cdot): Y \to \mathbb{R}$ is convex for fixed $x$.</p>

<p>Then we have that</p>

\[\max_{x \in X} \min_{y \in Y} f(x,y) = \min_{y \in Y} \max_{x \in X} f(x,y).\]

<h1 id="two-person-zero-sum-games">Two-Person Zero-Sum Games</h1>

<p>A <strong>two-person zero-sum game</strong> in strategic form is any $F$ of the form $F = (\{1, 2\}, C_1, C_2, u_1, u_2)$ such that</p>

\[u_2(c_1, c_2) = -u_1(c_1, c_2), \, \forall c_1 \in C_1, \, \forall c_2 \in C_2.\]

<p>The following theorem summarizes important mathematical properties of such games:</p>

<p>$(\sigma_1, \sigma_2)$ is a Nash equilibrium of a finite two-person zero-sum game $(\{1, 2\}, C_1, C_2, u_1, -u_1)$ if and only if</p>

\[\sigma_1 \in \arg\max_{\tau_1 \in \Delta(C_1)} \min_{\tau_2 \in \Delta(C_2)} u_1(\tau_1, \tau_2),\]

<p>and</p>

\[\sigma_2 \in \arg\min_{\tau_2 \in \Delta(C_2)} \max_{\tau_1 \in \Delta(C_1)} u_1(\tau_1, \tau_2).\]

<p>Furthermore, if $(\sigma_1, \sigma_2)$ is an equilibrium of this game, then</p>

\[u_1(\sigma_1, \sigma_2) = \max_{\tau_1 \in \Delta(C_1)} \min_{\tau_2 \in \Delta(C_2)} u_1(\tau_1, \tau_2) = \min_{\tau_2 \in \Delta(C_2)} \max_{\tau_1 \in \Delta(C_1)} u_1(\tau_1, \tau_2).\]

<h1 id="constructing-a-game-with-given-nash-equilibrium">Constructing a Game with Given Nash Equilibrium</h1>

<p>Suppose each player has $n$ policies and the payoff matrix is $\{\alpha_{ij}\}_{i=1}^n$.
Then,</p>

\[\begin{equation}
    \begin{aligned}
    \max_{\pi}\min_{\pi^{\prime}}
    \left\{
    \sum_{i=1}^n\sum_{j=1}^n\alpha_{ij}\pi_i\pi^{\prime}_j
    \right\}
    =&amp; \max_{\pi}\min_{\pi^{\prime}}
    \left\{
    \sum_{j=1}^n
    \left(\sum_{i=1}^n\alpha_{ij}\pi_i\right)\pi^{\prime}_j
    \right\} \\
    =&amp; \max_{\pi}\min_j
    \left\{
    \sum_{i=1}^n\alpha_{ij}\pi_i
    \right\} .
    \end{aligned}
\end{equation}\]

<p>Let us reformulated it into a convex optimization problem.</p>

\[\begin{array}{ll}
&amp;\text{(P)}\\  \min\limits_{\pi} &amp;\max_j \sum_{i=1}^n\alpha_{ij}\pi_i \\
 \text{subject to} 
&amp; -\pi_i \leq 0, \quad i = 1, \ldots, n \\
&amp; \sum_{i=1}^n \pi_i- 1=0
\end{array}\]

<p>Let us further reformulate this problem into the epigraph form by introducing a single varaible $t\in\RR$.</p>

\[\begin{array}{ll}
&amp;\text{(P)}\\  \min\limits_{\pi,t} &amp;t \\
 \text{subject to} 
&amp; \sum_{i=1}^n\alpha_{ij}\pi_i-t\leq 0, \quad j = 1, \ldots, n \\
&amp; -\pi_i \leq 0, \quad i = 1, \ldots, n \\
&amp; \sum_{i=1}^n \pi_i- 1=0
\end{array}\]

<p>We can easily see that Slater’s condition is satisfied for this problem, so the KKT points are equivalent to primal and dual solutions.</p>

\[\left\{\begin{matrix}
 u^*\geq 0 &amp;\sum_{i=1}^nu^*_i=1\\
 \pi^* \geq 0 &amp; \sum_{i=1}^n \pi_i^*=1\\
 \sum_{i=1}^n \pi_i^*\alpha_{ij}-t^*\leq0 &amp; u_j^*(\sum_{i=1}^n\pi_i^*\alpha_{ij}-t^*)=0\\
\tilde{u}^*\geq 0 &amp; \tilde{u}^*_i\pi^*_i=0\\
&amp;\sum_{i=1}^n\alpha_{ij}u_j^*-\tilde{u}_i^*=-v^*

\end{matrix}\right.\]

<h3 id="apllication-to-preference-matching">Apllication to Preference Matching</h3>

<p>Consider large $n\geq 3$. To do preference matching, we need to construct a reasonable payoff matrix $\{\alpha_{ij}\}_{i=1}^n$ with Nash equilibrium $\pi^*&gt;0$. In this case, the KKT conditions reduce to</p>

\[\left\{\begin{matrix}
 u^*\geq 0 &amp;\sum_{i=1}^nu^*_i=1\\
 \sum_{i=1}^n \pi_i^*\alpha_{ij}-t^*\leq0 &amp; u_j^*(\sum_{i=1}^n\pi_i^*\alpha_{ij}-t^*)=0\\
&amp;\sum_{i=1}^n\alpha_{ij}u_j^*=-v^*

\end{matrix}\right.\]

<p>It is worthy to note that the payoff matrix</p>

\[\alpha_{ij}=\pi_i^*+\pi_j^*-\delta_{ij}\]

<p>or</p>

\[\alpha_{ij}=-\frac{\pi_j^*}{\pi_i^*}+n\delta_{ij}\]

<p>guarantees that $ \pi^* $ is the Nash equilibrium by plugging into the KKT conditions. However, the first payoff matrix is symmetry, which is hard to interpret. And even worse, it depends on the $ \pi^* $ directly, which is not computable as the normalizing constant of  $ \pi^* $ is a summation of $n$ items. 
The second payoff matrix depends on $n$, which is also not computable.</p>

<p>From this we see that the payoff matrix should satisfies</p>
<ul>
  <li>$\alpha_{ii}=0$ for all $i\in [n]$. This is because we expect the diagonal elements of \(\{\alpha_{ij}\}_{i=1}^n\) to be the same, and substracting \(\\{1_{ij}\\}\) does not influence the Nash equilibrium.</li>
  <li>$\alpha_{ij}$ should only depends on $\frac{\pi_i}{\pi_j}$.</li>
</ul>

<p>Now we show that no reasonable $\alpha_{ij}$ can satisfies these two conditions.</p>

<p>Assume $\alpha_{ij}=f(\frac{\pi_i}{\pi_j})$ for some differentiable function $f$. 
Due to permutation symmetry, we seek solutions that satisfies \(\sum_{i=1}^n\pi^*_i\alpha_{ij}=t^*\) for all $j\in [n]$.</p>

<p>So we have</p>

\[\sum_{i\ne j} \pi_if(\frac{\pi_i}{\pi_j})=0\quad\forall j\in [n]\]

<p>Assume that $i\neq k\neq j$, and consider the infinitesimal variation $\pi_i\to \pi_i+\delta$, $\pi_k\to\pi_k-\delta$, keeping others still.
We have</p>

\[(\pi_i+\delta)f(\frac{\pi_i+\delta}{\pi_j})+(\pi_k-\delta)f(\frac{\pi_k-\delta}{\pi_j})=\pi_i f(\frac{\pi_i}{\pi_j})+\pi_k f(\frac{\pi_k}{\pi_j}),\]

<p>so</p>

\[f(\frac{\pi_i}{\pi_j})+\frac{\pi_i}{\pi_j}f'(\frac{\pi_i}{\pi_j})=f(\frac{\pi_k}{\pi_j})+\frac{\pi_k}{\pi_j}f'(\frac{\pi_k}{\pi_j}).\]

<p>For this to hold on all possible $\pi$, we must have</p>

\[f(x)+xf'(x)=C,\]

<p>i.e.</p>

\[f(x)=\frac{C_1}{x}+C_2.\]

<p>However, plugging this to \(\sum_{i\ne j} \pi_if(\frac{\pi_i}{\pi_j})=0\) yields a contradiction.</p>

            </article>
          


      </div>
    </div>

    <footer class="site-footer">

        <div class="wrap">

      
          <div class="footer-col-2 column">
            
          </div>
      
      
        </div>
      
      </footer>

    </body>
</html>
